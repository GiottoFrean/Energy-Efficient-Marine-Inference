# Energy-Efficient Marine Inference

Collecting marine data in-person is often infeasible at depth because it's difficult to provide life-support infrastructure in extreme pressure environments. Remotely operated underwater vehicles (ROUVs) offer an alternative, but require continuous communication with a surface operator. Such communication is limited by the rapid attenuation of signals in water and, if instead tethered, by the hydrodynamic drag imposed by any cable. These constraints motivate the use of autonomous underwater vehicles (AUVs) instead, which use onboard computers and decision-making algorithms.

AUVs rely on battery power. This means when designing these algorithms we need to pay careful attention to energy efficiency to avoid frequent retrieval, recharging, and redeployment. Maximizing data-per-unit-energy could involve:

1. Using low-energy sensors (e.g., hydrohpones instead of cameras).
2. Moving the AUV to a better location when replacing the batteries.
3. Having the AUV move to a better location itself.
4. Use multiple AUVs and have them communicate (minimally).

This repository contains a collection of exploratory notebooks about these options. Together, they amount to a brief study of energy-efficient marine inference. 

I focus on a single scenario where you want to conduct a population survey of deep-sea animals, estimating the distribution of species in a target region.

An overview of each notebook is given below.

---

## A - Species Inference from Movement Acoustics

Today, species identification in the deep ocean is typically performed using video cameras paired with artificial lighting. The system is dropped for a few days and left to record, before being retrieved and analysed. Not only is this approach is energy-intensive, but the artificial lighting disturbs some species and alters natural behaviour, biasing observations.

This notebook explores whether passive acoustics can provide a viable alternative. Hydrophones use far less energy than a camera and LED system. The core idea is to use the sound generated by animal movement to infer the species. I create simple synthetic creatures use their simulated acoustic responses to train a basic classifier as a proof-of-concept. Deployment would involve an initial calibration phase, during which recordings would need to be paired with visual labels, then followed by an extended autonomous operation.

Collection of training data would mean navigating to places with high animal density, which is covered in notebooks $B$, $D$, and $E$.

<p align="center">
  <img src="images/A%20-%20box_creature.gif" alt="Box creature" width="320"/>
  <img src="images/A%20-%20worm_creature.gif" alt="Worm creature" width="320"/>
</p>
<p align="center"><em>Simulated creatures and their movements within a hydrophone box.</em></p>

---

## B - Location Optimization with Gaussian Processes

This notebook provides an overview of Gaussian Process (GP) based optimization, emphasizing its efficiency in sample usage. If you imagine dropping a UAV and having it return a measure of animals-per-unit-time, you could take those measurements and use a GP to find the next best place to sample in order to collect the most data.

<p align="center">
  <img src="images/B%20-%20GP_progress.png" alt="Gaussian Process optimization progress" width="720"/>
</p>
<p align="center"><em>Evolution of the GP posterior and during optimization.</em></p>

---

## C - Distributed Event Inference with Communication Costs

Here, I do a slight pivot to study event detection in a network of stationary receivers operating in a noisy environment. For some species like whales observing them close-up is unlikely. Multiple agents might need to communicate to do reliable detection.

I compare:
- A standard centralized aggregation approach, and  
- A communication-efficient variant where nodes perform local inference and only transmit when a confidence threshold is exceeded.

The latter requires handling accidental or spurious triggers.

<p align="center">
  <img src="images/C%20-%20Noise_with_signal.png" alt="Noise with signal" width="320"/>
</p>
<p align="center"><em>Example of a weak signal embedded in background noise.</em></p>

<p align="center">
  <img src="images/C%20-%20array_and_signals.png" alt="Sensor array and signals" width="720"/>
</p>
<p align="center"><em>Sensor grid layout and corresponding received signals.</em></p>

<p align="center">
  <img src="images/C%20-%20score_grid.png" alt="Event score grid" width="320"/>
</p>
<p align="center"><em>Spatial score grid after distributed inference.</em></p>

---

## D - Location Optimization with an Explicit Energy Budget

This notebook extends the GP-based optimization demonstrated in B by explicitly incorporating energy constraints. While GP optimization is sample-efficient, we also might want to consider the movement cost between locations. While the cost of moving the boat and crew around is mainly determined by the number of samples you take (unless travelling miles), the cost of moving the AUV around is instead determined by distance.

I briefly review using mutual information for planning movement and then demonstrate that down-weighting expected improvement based on travel distance can improve the performance of an energy-constrained optimizer.

<p align="center">
  <img src="images/D%20-%20gp_with_budget.png" alt="GP optimization with energy budget" width="720"/>
</p>
<p align="center"><em>GP optimization when travel cost is explicitly penalized.</em></p>

---

## E - Optimization with Rare Events

This notebook addresses the challenge of navigating toward regions with high event rates when the underlying function is unobserved. In the scenario presented we never observe the true animal density, we have to infer, and then optimize it. 

The problem can be framed as inference over an inhomogeneous Poisson process, or a kind of continuous multi-armed bandit problem. I test an approach where observed events are converted into an events-per-unit-time signal along the robot's path, which is then used to reconstruct the full spatial intensity function.

<p align="center">
  <img src="images/E%20-%20path_true_function.png" alt="True underlying density" width="320"/>
</p>
<p align="center"><em>True underlying event intensity function.</em></p>

<p align="center">
  <img src="images/E%20-%20samples_path_example.png" alt="Samples along path" width="720"/>
</p>
<p align="center"><em>Observed events over time along the robotâ€™s trajectory.</em></p>

<p align="center">
  <img src="images/E%20-%20path_inferred_function.png" alt="Inferred density" width="320"/>
</p>
<p align="center"><em>Reconstructed spatial intensity function from sparse event data.</em></p>
